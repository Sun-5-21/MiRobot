# 小米杯初赛技术方案

## 主要 ROS 节点及 lcm 接口

在 ROS2 操作系统中，本项目主要利用了 ROS topic 话题通信节点中的 `Yaml_Parameter` 话题，负责切换 Cyberdog 的Mode和 ID，调用 `Laserscan` 话题，获取仿真雷达信息，调用 `/rgb_camera/image_raw` 话题，获取 RGB 相机信息，同时使用经过修改的 `gamepad_lcmt` 接口，方便有限状态机调整 Cyberdog 的运动状态。



（由于对仿真环境的接口不太熟悉，我们并不能成功通过数据手册上的运动接口来实现机器人控制，这为后续程序的实物迁移带来麻烦）

## 创新点/亮点概述

本项目使用了有限状态机技术以及闭环控制系统，通过 rgb 相机、tf 世界坐标变换和仿真雷达地形识别与测距，融合嵌入了高效易行的 PID 运动控制算法，在闭环控制系统中使用雷达测距技术修正可能发生的世界坐标偏移，使用 rgb 相机颜色识别技术辅助判断地形，以较小的训练成本和运行代价使得cyberdog 在大部分场景下能够顺利地运行。

### 3、关键技术

本项目的关键技术有：rgb 相机颜色识别技术、tf 世界坐标变换技术、仿真雷达地形识别技术、仿真雷达测距技术、世界坐标修正技术、有限状态机技术和闭环控制技术。

#### 3.1 环境感知

本项目基于仿真雷达和 tf 世界坐标系变换技术，简而言之，通过雷达获取障碍物精准距离，通过对世界坐标的验证与修复，加之 rgb 颜色识别辅助有限状态机判断当前障碍物

#### 3.2 导航及路径规划

利用tf世界坐标系变换技术，获取 cyberdog 的里程计数据，通过变换得到 cyberdog 的实时世界坐标（下附部分代码），再使用仿真雷达对固定点位的障碍物测距来辅助修正因颠簸或摔倒导致的里程计误差

获取并变换数据的代码如下：

```python
try:

# 这里假设机器人在 "base_link" 坐标系下，你需要根据实际情况修改

transform: TransformStamped = self.tf_buffer.lookup_transform(

'vodom', 'base_link', rclpy.time.Time())

self._pose[0] = transform.transform.translation.x + self.correct_x

self._pose[1] = transform.transform.translation.y + self.correct_y

self._pose[2] = Quaternion.get_euler(transform.transform.rotation)[2] + self.correct_th

# 发布PoseStamped消息

# self.get_logger().info(f"Published pose: {self._pose}")

except Exception as e:

self.get_logger().warn(f"Could not transform: {str(e)}")

```

在路径规划方面，我们采用了一种基于差速轮机器人的路径点跟踪算法，由距离误差得到线速度，由角度误差得到角速度，实现向目标点的逼近。同时我们将路径分为许多小点（目标点），机器人逐步移动到每个目标点，直到实现以特定路径到达最终目的地。这种方法通过以下步骤实现：

1. **路径分割**：将整个路径分为多个小的目标点（`cor`）。
2. **逐点跟踪**：机器人逐个移动到每个目标点（`goal_cor`），直到达到最终目的地。
3. **位置更新**：在每个目标点，计算机器人的速度和方向（`get_vel`）并发布控制命令（`pub_vel`），使机器人朝向目标点移动。
4. **距离检查**：检查机器人与当前目标点之间的距离（`rho`）。当距离小于一定阈值时，移动到下一个目标点。
由于cyberdog的里程计存在误差，误差会随着cyberdog的运动而累积，因此我们会在关键位置，根据雷达数据和障碍物的位置对里程计数据进行修正。

```
    def correct_pose(self,pose):
        self.correct_x =  pose[0] - self._pose[0] 
        self.correct_y =  pose[1] - self._pose[1]
        self.correct_th = pose[2] - self._pose[2]
        print("self.correct_x",self.correct_x)
        print("self.correct_y",self.correct_y)
        print("self.correct_th",self.correct_th)
```

```
def correct_pose_x(x):
    dis = Control.min_front_range
    print("dis", dis)
    pose = copy.deepcopy(Control._pose)
    pose[0] = x - dis
    print("pose[0]",pose[0])
    Control.correct_pose(pose)

def correct_pose_y(y):
    dis = Control.min_front_range
    print("dis", dis)
    pose = Control._pose
    pose[1] = y - dis
    print("pose[1]",pose[0])
    Control.correct_pose(pose)
```


#### 3.3 运动控制

核心技术围绕：**有限状态机** + **gamepad_control** + **PID 控制**展开，通过有限状态机判断 cyberdog 运动状态，在大部分直线平地路径上使用 PID 控制算法，借鉴了 `/home/cyberdog_sim/cyberdog_simulator/cyberdog_` `example/keybroad_commander.cpp` 中提供的 lcm 运动控制样例，实现对 cyberdog 运动过程的控制。关于对源码的修改以及开源算法的利用，将在 3.4 节中介绍。由于手柄控制例程存在局限性,无法调整cyberdog的step_height,所以我修改了command_interface.cpp,使得我们可以通过gamepad_lcmt调整step_height

```
void CommandInterface::Gamepad2Cmd( long int* control_mode, long int* gait_id, const RobotType& robotType ) {

    if ( gamepad_cmd_.back ) {
        *control_mode = MotionMode::kOff;
    }
    if ( gamepad_cmd_.a ) {
        *control_mode = MotionMode::kPureDamper;
    }
    if ( gamepad_cmd_.b ) {
        *control_mode = MotionMode::kRecoveryStand;
    }
    if ( gamepad_cmd_.x ) {
        *control_mode = MotionMode::kQpStand;
    }
    if ( gamepad_cmd_.y ) {
        *control_mode = MotionMode::kLocomotion;
    }
    if ( gamepad_cmd_.rightBumper ) {
        *gait_id = GaitId::kTrot10v4;
    }
    if ( gamepad_cmd_.leftBumper ) {
        *gait_id = GaitId::kTrotFast;
    }
    // // default is trot
    if ( *gait_id == 0 && *control_mode == MotionMode::kLocomotion ) *gait_id = GaitId::kTrot10v5;
    
    // if (gamepad_cmd_.rightBumper != 0) *gait_id = gamepad_cmd_.rightBumper;
    cmd_cur_.mode       = *control_mode;
    cmd_cur_.gait_id    = *gait_id;
    cmd_cur_.cmd_source = kGamepadCmd;

    if ( cmd_cur_.mode == MotionMode::kQpStand ) {  // QP stand
        // rpy desired
        // TODO: deadband
        cmd_cur_.vel_des[ 0 ] = 0;
        cmd_cur_.vel_des[ 1 ] = 0; 
        cmd_cur_.vel_des[ 2 ] = 0;
        cmd_cur_.rpy_des[ 0 ] = gamepad_cmd_.leftStickAnalog[ 0 ] * 0.6;   // roll
        cmd_cur_.rpy_des[ 1 ] = gamepad_cmd_.leftStickAnalog[ 1 ] * 0.6;   // pitch
        cmd_cur_.rpy_des[ 2 ] = gamepad_cmd_.rightStickAnalog[ 1 ] * 0.6;  // yaw
        if ( cmd_cur_.gait_id == 1 || cmd_cur_.gait_id == 3 )
            cmd_cur_.pos_des[ 2 ] = 0.1 * gamepad_cmd_.rightStickAnalog[ 0 ];
        else
            cmd_cur_.pos_des[ 2 ] = ( ( robotType == RobotType::CYBERDOG2 ) ? 0.24 : 0.32 ) + 0.1 * gamepad_cmd_.rightStickAnalog[ 0 ];
        cmd_cur_.contact = 0x0F;
    }
    else if ( cmd_cur_.mode == MotionMode::kLocomotion || cmd_cur_.mode == MotionMode::kRlRapid ) {
        // x,y, yaw velocity command
        cmd_cur_.vel_des[ 0 ]     = gamepad_cmd_.leftStickAnalog[ 0 ];
        cmd_cur_.vel_des[ 1 ]     = gamepad_cmd_.leftStickAnalog[ 1 ];
        cmd_cur_.vel_des[ 2 ]     = gamepad_cmd_.leftTriggerAnalog;
        // cmd_cur_.vel_des[ 2 ]     = -gamepad_cmd_.rightStickAnalog[ 0 ];
        cmd_cur_.rpy_des[ 0 ]     = 0;
        cmd_cur_.rpy_des[ 2 ]     = 0;
        cmd_cur_.rpy_des[ 1 ]     = 0;
        // cmd_cur_.pos_des[ 2 ]     = ( ( robotType == RobotType::CYBERDOG2 ) ? 0.25 : 0.32 );
        cmd_cur_.pos_des[ 2 ]     = ( ( robotType == RobotType::CYBERDOG2 ) ? 0.25 : 0.32 );
        // if (gamepad_cmd_.rightTriggerAnalog != 0) cmd_cur_.step_height[ 0 ] = gamepad_cmd_.rightTriggerAnalog;
        // else cmd_cur_.step_height[ 0 ] = 0.06;
    }
    if (gamepad_cmd_.rightTriggerAnalog != 0) cmd_cur_.step_height[ 0 ] = gamepad_cmd_.rightTriggerAnalog;
        else cmd_cur_.step_height[ 0 ] = 0.10;
    if ( cmd_cur_.duration == 0 ) {
        if ( cmd_cur_.mode == MotionMode::kMotion && motion_trigger_ > 0 ) {
            return;k
        }
        else {
            while ( !cmd_list_.empty() )
                cmd_list_.pop();
        }
    }
    interface_iter_ = 0;
    cmd_list_.push( cmd_cur_ );
}
```

```
GamepadCommand LCMHandler::ReceiveGPC()
    {
        lcm_.handle();
        gamepad_command_.a=lcm_gamepad_.a;
        gamepad_command_.b=lcm_gamepad_.b;
        gamepad_command_.x=lcm_gamepad_.x;
        gamepad_command_.y=lcm_gamepad_.y;
        gamepad_command_.leftStickAnalog[0]=lcm_gamepad_.leftStickAnalog[0];
        gamepad_command_.leftStickAnalog[1]=lcm_gamepad_.leftStickAnalog[1];
        gamepad_command_.rightStickAnalog[0]=lcm_gamepad_.rightStickAnalog[0];
        gamepad_command_.rightStickAnalog[1]=lcm_gamepad_.rightStickAnalog[1];
        gamepad_command_.leftTriggerAnalog=lcm_gamepad_.leftTriggerAnalog;
        gamepad_command_.rightTriggerAnalog=lcm_gamepad_.rightTriggerAnalog;

        return gamepad_command_;
    }
```
#### 3.4 特殊地形处理

下面给出每个地形的识别方式（特别说明：由于技术原因，本项目放弃石子路以及台阶部分）

##### 1) 斜坡：	关键：打开了 cyberdog 开源代码中 `USE_TERRAIN_DETECTER` 宏关联代码

利用坐标确定斜坡定位，同时使用仿真雷达辅助确认与斜面距离，在打开宏关联代码并设置斜坡倾斜弧度的情况下，实现上下坡定位

##### 2) 转角：	关键：使用 cyberdog_preinstalled_motion 中的 `jump_ctrl_yaw_p90` 步态

主要利用坐标确认到达转角，利用仿真雷达辅助修正世界坐标，在特定距离调用内置步态`jump_ctrl_yaw_p90`,来实现转角转弯。步态`jump_ctrl_yaw_p90`并不是精准的90度旋转,所以我们在此基础上会利用里程计数据进行微调,确保到达精确的角度

```
def rotate(self,theta):
	# print("theta",theta,"self._pose[2]",self._pose[2])
	theta = theta - self._pose[2]
	if theta < -pi:
	theta += 2*pi
	elif theta > pi:
	theta -= 2*pi
	self.diff_theta = theta
	self.ang = self.kp2 * theta
	self.ang = self.ang if abs(self.ang)< self.max_ang else np.sign(self.ang)*self.max_ang
	# print("self.vel",self.vel,"self.ang",self.ang)

  

def correct_yaw(self,theta):
	self.rotate(theta)
	while (abs(self.diff_theta) > 0.08) :
	print("diff_yaw",abs(self.diff_theta))
	self.rotate(theta)
	self.vel = 0
	self.pub_vel()
```

##### 3) 石板、崎岖地形与沙地：	关键：使用 cyberdog_preinstalled_motion 中的 `locomotion` 步态

同上，我们依旧主要利用坐标来确认，在特定的距离调用 `locomotion` 模式的TrotSlow步态，以较缓慢的速度和较低的步频通过这些地形，并且启用USE_TERRAIN_DETECTER宏相关函数来适应崎岖的地面。

##### 4) 绕障：	关键：使用 stanley 运控算法

控制算法会在机器人到达障碍物前方的一定距离时启动。安全路径被分解成一系列紧密相连的小点，每个小点都代表一个机器人需要到达的目标点。机器人通过不断修正方向，逐步朝着下一个目标点移动，最终绕过障碍物。

这种方法的优点在于，它能够细化路径规划，使得机器人在复杂环境中移动更加平滑和精准。状态机将调用对应的算法模块，确保机器人能够安全高效地通过障碍物。

##### 5) 连续碰撞

对于连续碰撞模块，状态机将调用 rgb 相机模块进行颜色识别，由于我们确定RGB相机画面中心一定为红色或绿色，因此为了简化代码，我们可以比较RGB三通道的大小来判断面前是红色还是绿色。

```
    def image_callback(self, msg):
        try:
            # 获取图像尺寸
            height = msg.height
            width = msg.width
            channels = 3  # 三通道RGB格式

            # 计算中心像素的索引
            center_x = width // 2
            center_y = height // 2
            center_index = (center_y * width + center_x) * channels # 因为是一维数组，RGB三个顺序排列所以要乘以三

            # 获取中心像素的RGB值
            data = msg.data 
            # print(data)
            r = data[center_index]
            g = data[center_index + 1]
            b = data[center_index + 2]

            is_green = g > r and g > b
            print("r",r,"g",g,"b",b)
            print("is_green",is_green)
            if is_green:
                self.is_green = True
                self.is_red = False
            else:
                self.is_green = False
                self.is_red = True

        except Exception as e:
            self.get_logger().error(f"处理图像时发生错误: {e}")
```

同时，为了简化决策过程，我们将赛道一分为二，分为左右两个状态,状态机将根据 rgb 颜色识别结果和当前所在的位置状态来控制 cyberdog 选择不同的赛道区域来进入，最终到达终点
```
def mode6():
    global mode,goal_cor,debug
    while Control._pose[1] > 1:
        Control.vel = 0.2
        Control.rotate(-math.pi/2)
        Control.pub_vel()
        # print("color_recognizer_node.is_green",color_recognizer_node.is_red)
        if Control.is_red:
            if Control.status:
                left_forward()
                Control.status = 0
            else:
                right_forward()
                Control.status = 1
    example_node.switch_mode(12)
    sleep(1)
    example_node.switch_mode(7)

```

# 小米杯决赛技术方案

程序迁移到实物上的困难：

1. 由于手机遥控使用的是gamepad_lcmt接口，所以我们不能擅自修改，不过幸好实物阶段，开发者手册上的所有运动接口均能正常使用。重新编写程序的运动接口程序后机器人可以正常运动。
2. 程序过于依赖坐标的准确性，在仿真环境中里程计数据是非常精准的，在有限距离下并不会出现很大的偏差，且能被校准。但在实物阶段，机器人下位机的里程计数据不太准确，尤其是当我们将机器人搬移到起点后机器人的偏航角和坐标会出现很大很大的偏差（或许是机器人的轮腿里程计不工作），若想要初始化里程计数据，只能重启机器人，耗时低效。最终，我们编写了一个坐标修正程序，每次执行时会根据输入正确的偏航角和坐标，进行机器人坐标系的旋转平移，最后得到正确坐标系。
3. 对于雷达数据的利用率还是不足（没使用侧面雷达），最终在决赛还是犯了不少错，基于坐标的PID运动控制不可靠。